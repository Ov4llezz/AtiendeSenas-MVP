{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# ü§ñ AtiendeSenas - Entrenamiento VideoMAE en Google Colab\n",
        "\n",
        "**Proyecto**: Reconocimiento de Lengua de Se√±as con VideoMAE\n",
        "\n",
        "**Autor**: Rafael Ovalle - Tesis UNAB\n",
        "\n",
        "**Datasets disponibles**:\n",
        "- WLASL100: 100 clases, ~1,000 videos\n",
        "- WLASL300: 300 clases, ~2,790 videos\n",
        "\n",
        "---\n",
        "\n",
        "## üìã √çndice\n",
        "1. Configuraci√≥n inicial\n",
        "2. Clonar repositorio\n",
        "3. Instalar dependencias\n",
        "4. Verificar datasets\n",
        "5. Entrenamiento\n",
        "6. Evaluaci√≥n\n",
        "7. Visualizaci√≥n de resultados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhpDpoqQ1dMy",
        "outputId": "274b7445-7094-4814-b8a8-5cddd48294b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1Ô∏è‚É£ Configuraci√≥n Inicial\n",
        "\n",
        "### Verificar GPU disponible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "\n",
        "print(\"Python version:\", sys.version)\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    print(\"CUDA version:\", torch.version.cuda)\n",
        "    print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1024**3, \"GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: GPU no disponible. El entrenamiento ser√° MUY lento.\")\n",
        "    print(\"Ve a Runtime > Change runtime type > GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clone_repo"
      },
      "source": [
        "## 2Ô∏è‚É£ Clonar Repositorio\n",
        "\n",
        "Clona tu repositorio de GitHub con el c√≥digo y datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone"
      },
      "outputs": [],
      "source": [
        "# Configurar Git (opcional, para commits)\n",
        "!git config --global user.email \"your.email@example.com\"\n",
        "!git config --global user.name \"Your Name\"\n",
        "\n",
        "# Clonar el repositorio\n",
        "!git clone https://github.com/Ov4llezz/AtiendeSenas-MVP.git\n",
        "\n",
        "# Cambiar al directorio del proyecto\n",
        "%cd AtiendeSenas-MVP\n",
        "\n",
        "# Verificar que estamos en el directorio correcto\n",
        "!pwd\n",
        "!ls -la\n",
        "\n",
        "\n",
        "\n",
        "%cd /content\n",
        "!rm -rf AtiendeSenas-MVP\n",
        "\n",
        "!git clone https://github.com/Ov4llezz/AtiendeSenas-MVP.git\n",
        "\n",
        "%cd /content/AtiendeSenas-MVP\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install_deps"
      },
      "source": [
        "## 3Ô∏è‚É£ Instalar Dependencias\n",
        "\n",
        "Instala todas las librer√≠as necesarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Instalar dependencias desde requirements.txt si existe\n",
        "!pip install -q transformers==4.36.0\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q matplotlib seaborn\n",
        "!pip install -q tensorboard\n",
        "!pip install -q tqdm\n",
        "\n",
        "print(\"‚úÖ Dependencias instaladas correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "verify_datasets"
      },
      "source": [
        "## 4Ô∏è‚É£ Verificar Datasets\n",
        "\n",
        "Verifica que los datasets est√©n correctamente configurados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify"
      },
      "outputs": [],
      "source": [
        "# Ejecutar script de verificaci√≥n\n",
        "!python scripts/verify_datasets.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "check_data"
      },
      "source": [
        "### Revisar estructura de datos manualmente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_structure"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def count_videos(dataset_path):\n",
        "    \"\"\"Cuenta videos en cada split\"\"\"\n",
        "    splits = ['train', 'val', 'test']\n",
        "    print(f\"\\nüìÅ Dataset: {dataset_path}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for split in splits:\n",
        "        split_path = os.path.join(dataset_path, 'dataset', split)\n",
        "        if os.path.exists(split_path):\n",
        "            videos = [f for f in os.listdir(split_path) if f.endswith('.mp4')]\n",
        "            print(f\"{split:5s}: {len(videos):4d} videos\")\n",
        "        else:\n",
        "            print(f\"{split:5s}: ‚ùå No existe\")\n",
        "\n",
        "# Verificar ambos datasets\n",
        "count_videos('data/wlasl100')\n",
        "count_videos('data/wlasl300')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section"
      },
      "source": [
        "## 5Ô∏è‚É£ Entrenamiento\n",
        "\n",
        "### Configuraci√≥n de Hiperpar√°metros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        "# ========== CONFIGURACI√ìN ==========\n",
        "# Cambia estos valores seg√∫n tus necesidades\n",
        "\n",
        "DATASET = \"wlasl100\"  # \"wlasl100\" o \"wlasl300\"\n",
        "BATCH_SIZE = 16       # Reduce si tienes problemas de memoria (ej: 8, 12)\n",
        "MAX_EPOCHS = 30       # N√∫mero de epochs\n",
        "LEARNING_RATE = 1e-4  # Learning rate\n",
        "PATIENCE = 5          # Early stopping patience\n",
        "\n",
        "print(f\"\"\"\\n{'='*60}\n",
        "CONFIGURACI√ìN DE ENTRENAMIENTO\n",
        "{'='*60}\n",
        "Dataset:          {DATASET}\n",
        "Batch size:       {BATCH_SIZE}\n",
        "Max epochs:       {MAX_EPOCHS}\n",
        "Learning rate:    {LEARNING_RATE:.1e}\n",
        "Patience:         {PATIENCE}\n",
        "{'='*60}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_model"
      },
      "source": [
        "### Entrenar Modelo\n",
        "\n",
        "**Nota**: Este proceso puede tomar varias horas dependiendo del dataset y GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "# Entrenar modelo\n",
        "!python scripts/train.py \\\n",
        "    --dataset {DATASET} \\\n",
        "    --batch_size {BATCH_SIZE} \\\n",
        "    --max_epochs {MAX_EPOCHS} \\\n",
        "    --lr {LEARNING_RATE} \\\n",
        "    --patience {PATIENCE} \\\n",
        "    --class_weighted true \\\n",
        "    --early_stopping true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tensorboard_section"
      },
      "source": [
        "### Visualizar Training con TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tensorboard"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quick_train"
      },
      "source": [
        "### üöÄ Entrenamiento R√°pido (Para Testing)\n",
        "\n",
        "Si solo quieres probar que todo funciona:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quick_test"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento de prueba r√°pido (solo 2 epochs)\n",
        "!python scripts/train.py \\\n",
        "    --dataset wlasl100 \\\n",
        "    --batch_size 8 \\\n",
        "    --max_epochs 2 \\\n",
        "    --lr 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation_section"
      },
      "source": [
        "## 6Ô∏è‚É£ Evaluaci√≥n\n",
        "\n",
        "### Listar Modelos Entrenados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "list_runs"
      },
      "outputs": [],
      "source": [
        "# Ver todos los runs disponibles\n",
        "!python scripts/test.py --list-runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluate_model"
      },
      "source": [
        "### Evaluar Modelo\n",
        "\n",
        "Selecciona el Run ID del modelo que quieres evaluar (normalmente el m√°s reciente es run-id 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate"
      },
      "outputs": [],
      "source": [
        "# Evaluar el modelo m√°s reciente (run-id 1)\n",
        "RUN_ID = 1\n",
        "\n",
        "!python scripts/test.py --run-id {RUN_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluate_custom"
      },
      "source": [
        "### Evaluar Checkpoint Espec√≠fico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_checkpoint"
      },
      "outputs": [],
      "source": [
        "# Buscar checkpoints disponibles\n",
        "!ls -lh models/checkpoints/*/best_model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eval_specific"
      },
      "outputs": [],
      "source": [
        "# Evaluar checkpoint espec√≠fico\n",
        "CHECKPOINT_PATH = \"models/checkpoints/run_XXXXXX_XXXXXX/best_model.pt\"  # Cambiar por tu path\n",
        "\n",
        "!python scripts/test.py --checkpoint_path {CHECKPOINT_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization_section"
      },
      "source": [
        "## 7Ô∏è‚É£ Visualizaci√≥n de Resultados\n",
        "\n",
        "### Ver Matriz de Confusi√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_confusion"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "# Buscar la √∫ltima matriz de confusi√≥n generada\n",
        "confusion_matrices = sorted(glob.glob('evaluation_results/confusion_matrix_*.png'), reverse=True)\n",
        "\n",
        "if confusion_matrices:\n",
        "    print(f\"üìä Mostrando: {confusion_matrices[0]}\")\n",
        "    display(Image(filename=confusion_matrices[0]))\n",
        "else:\n",
        "    print(\"‚ùå No se encontraron matrices de confusi√≥n. Ejecuta la evaluaci√≥n primero.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "show_metrics"
      },
      "source": [
        "### Ver M√©tricas Detalladas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "metrics"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import glob\n",
        "\n",
        "# Buscar el √∫ltimo reporte JSON\n",
        "reports = sorted(glob.glob('evaluation_results/evaluation_report_*.json'), reverse=True)\n",
        "\n",
        "if reports:\n",
        "    with open(reports[0], 'r') as f:\n",
        "        metrics = json.load(f)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä M√âTRICAS DE EVALUACI√ìN\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nDataset: {metrics['dataset_info']['dataset']}\")\n",
        "    print(f\"Muestras: {metrics['dataset_info']['test_samples']}\")\n",
        "    print(f\"Clases: {metrics['dataset_info']['num_classes']}\")\n",
        "\n",
        "    print(\"\\n--- M√©tricas Generales ---\")\n",
        "    print(f\"Accuracy Total:     {metrics['overall_metrics']['total_accuracy']:.2f}%\")\n",
        "    print(f\"Precision (Macro):  {metrics['overall_metrics']['precision_macro']:.2f}%\")\n",
        "    print(f\"Recall (Macro):     {metrics['overall_metrics']['recall_macro']:.2f}%\")\n",
        "    print(f\"F1-Score (Macro):   {metrics['overall_metrics']['f1_macro']:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Top-K Accuracy ---\")\n",
        "    for k, v in metrics['top_k_accuracies'].items():\n",
        "        print(f\"{k}: {v:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Top 10 Mejores Clases (por F1-Score) ---\")\n",
        "    per_class = metrics['per_class_metrics']\n",
        "    sorted_classes = sorted(per_class.items(), key=lambda x: x[1]['f1_score'], reverse=True)[:10]\n",
        "    for class_id, class_metrics in sorted_classes:\n",
        "        print(f\"Clase {class_id}: F1={class_metrics['f1_score']:.2f}%, \"\n",
        "              f\"Precision={class_metrics['precision']:.2f}%, \"\n",
        "              f\"Recall={class_metrics['recall']:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Top 10 Peores Clases (por F1-Score) ---\")\n",
        "    sorted_classes = sorted(per_class.items(), key=lambda x: x[1]['f1_score'])[:10]\n",
        "    for class_id, class_metrics in sorted_classes:\n",
        "        print(f\"Clase {class_id}: F1={class_metrics['f1_score']:.2f}%, \"\n",
        "              f\"Precision={class_metrics['precision']:.2f}%, \"\n",
        "              f\"Recall={class_metrics['recall']:.2f}%\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(\"‚ùå No se encontraron reportes. Ejecuta la evaluaci√≥n primero.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plot_training"
      },
      "source": [
        "### Graficar Curvas de Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_curves"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "import glob\n",
        "\n",
        "def plot_training_curves(log_dir):\n",
        "    \"\"\"Grafica curvas de loss y accuracy desde TensorBoard logs\"\"\"\n",
        "    ea = event_accumulator.EventAccumulator(log_dir)\n",
        "    ea.Reload()\n",
        "\n",
        "    # Obtener m√©tricas disponibles\n",
        "    tags = ea.Tags()['scalars']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot Loss\n",
        "    if 'train_loss' in tags and 'val_loss' in tags:\n",
        "        train_loss = [(s.step, s.value) for s in ea.Scalars('train_loss')]\n",
        "        val_loss = [(s.step, s.value) for s in ea.Scalars('val_loss')]\n",
        "\n",
        "        axes[0].plot([s[0] for s in train_loss], [s[1] for s in train_loss], label='Train Loss')\n",
        "        axes[0].plot([s[0] for s in val_loss], [s[1] for s in val_loss], label='Val Loss')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Loss')\n",
        "        axes[0].set_title('Training and Validation Loss')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "\n",
        "    # Plot Accuracy\n",
        "    if 'train_accuracy' in tags and 'val_accuracy' in tags:\n",
        "        train_acc = [(s.step, s.value) for s in ea.Scalars('train_accuracy')]\n",
        "        val_acc = [(s.step, s.value) for s in ea.Scalars('val_accuracy')]\n",
        "\n",
        "        axes[1].plot([s[0] for s in train_acc], [s[1] for s in train_acc], label='Train Acc')\n",
        "        axes[1].plot([s[0] for s in val_acc], [s[1] for s in val_acc], label='Val Acc')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Accuracy (%)')\n",
        "        axes[1].set_title('Training and Validation Accuracy')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Buscar el √∫ltimo run\n",
        "runs = sorted(glob.glob('runs/run_*'), reverse=True)\n",
        "if runs:\n",
        "    print(f\"üìà Graficando: {runs[0]}\")\n",
        "    try:\n",
        "        plot_training_curves(runs[0])\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error al graficar: {e}\")\n",
        "        print(\"Usa TensorBoard para ver las curvas de entrenamiento.\")\n",
        "else:\n",
        "    print(\"‚ùå No se encontraron logs de entrenamiento.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_section"
      },
      "source": [
        "## üíæ Descargar Resultados\n",
        "\n",
        "### Comprimir y Descargar Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_models"
      },
      "outputs": [],
      "source": [
        "# Comprimir modelos\n",
        "!tar -czf models_checkpoints.tar.gz models/checkpoints/\n",
        "\n",
        "# Comprimir resultados de evaluaci√≥n\n",
        "!tar -czf evaluation_results.tar.gz evaluation_results/\n",
        "\n",
        "print(\"‚úÖ Archivos comprimidos:\")\n",
        "!ls -lh *.tar.gz\n",
        "\n",
        "# Para descargar, haz clic derecho en los archivos en el panel izquierdo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_files"
      },
      "source": [
        "### Descargar Archivos Individuales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_individual"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Descargar el mejor modelo\n",
        "best_models = glob.glob('models/checkpoints/*/best_model.pt')\n",
        "if best_models:\n",
        "    files.download(best_models[0])\n",
        "\n",
        "# Descargar matriz de confusi√≥n\n",
        "confusion_matrices = glob.glob('evaluation_results/confusion_matrix_*.png')\n",
        "if confusion_matrices:\n",
        "    files.download(confusion_matrices[0])\n",
        "\n",
        "# Descargar reporte de evaluaci√≥n\n",
        "reports = glob.glob('evaluation_results/evaluation_report_*.json')\n",
        "if reports:\n",
        "    files.download(reports[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utils_section"
      },
      "source": [
        "## üîß Utilidades\n",
        "\n",
        "### Monitorear Uso de GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu_monitor"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clear_memory"
      },
      "source": [
        "### Limpiar Memoria GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clear_gpu"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "# Limpiar cache de GPU\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"‚úÖ Memoria GPU liberada\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mount_drive"
      },
      "source": [
        "### Montar Google Drive (Para guardar resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drive_mount"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copiar checkpoints a Drive\n",
        "!cp -r models/checkpoints /content/drive/MyDrive/AtiendeSenas_Checkpoints/\n",
        "!cp -r evaluation_results /content/drive/MyDrive/AtiendeSenas_Results/\n",
        "\n",
        "print(\"‚úÖ Resultados copiados a Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshooting"
      },
      "source": [
        "## ‚ö†Ô∏è Soluci√≥n de Problemas\n",
        "\n",
        "### Error: Out of Memory\n",
        "- Reduce `BATCH_SIZE` (ej: de 16 a 8 o 12)\n",
        "- Limpia memoria GPU ejecutando la celda de \"Limpiar Memoria GPU\"\n",
        "- Reinicia el runtime: Runtime > Restart runtime\n",
        "\n",
        "### Error: No GPU available\n",
        "- Ve a Runtime > Change runtime type\n",
        "- Selecciona GPU como Hardware accelerator\n",
        "- Guarda y reconecta\n",
        "\n",
        "### Sesi√≥n de Colab se desconecta\n",
        "- Colab tiene l√≠mite de tiempo (12h para usuarios gratuitos)\n",
        "- Guarda checkpoints frecuentemente\n",
        "- Usa Google Drive para respaldos\n",
        "\n",
        "### Videos no se cargan\n",
        "- Verifica que los videos est√©n en el repositorio\n",
        "- Ejecuta `verify_datasets.py` para diagn√≥stico\n",
        "- Revisa los paths en `WLASLDataset.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notes"
      },
      "source": [
        "## üìù Notas Importantes\n",
        "\n",
        "1. **Tiempo de Entrenamiento**:\n",
        "   - WLASL100: ~2-4 horas (30 epochs)\n",
        "   - WLASL300: ~6-12 horas (30 epochs)\n",
        "   - Depende de la GPU disponible\n",
        "\n",
        "2. **Checkpoints**:\n",
        "   - Se guardan autom√°ticamente cada 5 epochs\n",
        "   - El mejor modelo se guarda en `best_model.pt`\n",
        "   - Puedes resumir entrenamiento con `--resume`\n",
        "\n",
        "3. **Early Stopping**:\n",
        "   - Se detiene si no mejora en 5 epochs (configurable)\n",
        "   - Basado en validation loss\n",
        "\n",
        "4. **Recursos de Colab**:\n",
        "   - GPU gratuita: T4 (16GB)\n",
        "   - L√≠mite de tiempo: 12 horas continuas\n",
        "   - Guarda resultados frecuentemente\n",
        "\n",
        "---\n",
        "\n",
        "**¬°Buena suerte con el entrenamiento! üöÄ**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}