{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéì VideoMAE - Sign Language Recognition (WLASL)\n",
    "## Complete Training & Evaluation Pipeline for Thesis\n",
    "\n",
    "**Autor:** Rafael Ovalle - Tesis UNAB  \n",
    "**Dataset:** WLASL100/WLASL300 (American Sign Language)  \n",
    "**Modelo:** VideoMAE (MCG-NJU/videomae-base-finetuned-kinetics)\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Features de este Notebook:\n",
    "\n",
    "- ‚úÖ **Configuraci√≥n Flexible:** Elige entre V1 (baseline) o V2 (experimental)\n",
    "- ‚úÖ **M√∫ltiples Datasets:** WLASL100 (100 clases) o WLASL300 (300 clases)\n",
    "- ‚úÖ **Entrenamiento Completo:** Con early stopping, checkpointing y TensorBoard\n",
    "- ‚úÖ **Evaluaci√≥n Detallada:** Accuracy, Precision, Recall, F1, Top-K, Confusion Matrix\n",
    "- ‚úÖ **Visualizaciones:** Gr√°ficos de entrenamiento, matrices de confusi√≥n, an√°lisis por clase\n",
    "- ‚úÖ **Exportaci√≥n Autom√°tica:** Resultados en JSON, TXT, im√°genes y modelo final\n",
    "- ‚úÖ **Integraci√≥n Drive:** Guarda todo en tu Google Drive autom√°ticamente\n",
    "- ‚úÖ **Optimizaci√≥n HP:** B√∫squeda de hiperpar√°metros (opcional)\n",
    "\n",
    "---\n",
    "\n",
    "### üóÇÔ∏è Configuraciones Disponibles:\n",
    "\n",
    "| Configuraci√≥n | Dataset | Train Videos | Val Videos | Test Videos | Uso Recomendado |\n",
    "|---------------|---------|--------------|------------|-------------|------------------|\n",
    "| **V1 - WLASL100** | 100 clases | 807 | 194 | 117 | Baseline, experimentaci√≥n |\n",
    "| **V2 - WLASL100** | 100 clases | 1,001 | 117 | 117 | Maximizar datos |\n",
    "| **V1 - WLASL300** | 300 clases | 1,959 | 557 | 271 | Baseline, experimentaci√≥n |\n",
    "| **V2 - WLASL300** | 300 clases | 2,516 | 271 | 271 | Maximizar datos |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Diferencias V1 vs V2:\n",
    "\n",
    "**V1 (Baseline):**\n",
    "- Train/Val/Test separados e independientes\n",
    "- Regularizaci√≥n activa (weight decay, label smoothing, class weights)\n",
    "- Batch size: 16, LR: 1e-4\n",
    "- Ideal para experimentaci√≥n y tuning de hiperpar√°metros\n",
    "\n",
    "**V2 (Experimental):**\n",
    "- Train+Val combinados, Test usado como validaci√≥n\n",
    "- Sin regularizaci√≥n expl√≠cita (conf√≠a en m√°s datos)\n",
    "- Batch size: 6, LR: 1e-5\n",
    "- Ideal para modelo final con m√°ximos datos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "# 1Ô∏è‚É£ Setup Inicial\n",
    "\n",
    "## 1.1 Verificar GPU y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Verificar GPU disponible\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "## 1.2 Instalar Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Instalar dependencias necesarias\n",
    "!pip install transformers==4.36.0\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install opencv-python-headless\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib seaborn\n",
    "!pip install tensorboard\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "\n",
    "print(\"‚úÖ Todas las dependencias instaladas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## 1.3 Importar Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers import VideoMAEForVideoClassification\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    top_k_accuracy_score\n",
    ")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configurar matplotlib para mejor visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drive"
   },
   "source": [
    "## 1.4 Montar Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Crear carpeta de trabajo en Drive\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive/TESIS_WLASL\"\n",
    "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Google Drive montado en: {DRIVE_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "# 2Ô∏è‚É£ Configuraci√≥n del Experimento\n",
    "\n",
    "## 2.1 Seleccionar Configuraci√≥n\n",
    "\n",
    "**üéØ Instrucciones:**\n",
    "1. Elige el dataset (WLASL100 o WLASL300)\n",
    "2. Elige la versi√≥n (V1 baseline o V2 experimental)\n",
    "3. Ajusta hiperpar√°metros si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "select_config"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#   CONFIGURACI√ìN PRINCIPAL\n",
    "# ============================================================\n",
    "\n",
    "# üéØ SELECCIONA TU CONFIGURACI√ìN AQU√ç:\n",
    "DATASET_TYPE = \"wlasl100\"  # Opciones: \"wlasl100\" o \"wlasl300\"\n",
    "VERSION = \"v1\"             # Opciones: \"v1\" (baseline) o \"v2\" (experimental)\n",
    "\n",
    "# Configurar autom√°ticamente basado en selecci√≥n\n",
    "if DATASET_TYPE == \"wlasl100\":\n",
    "    NUM_CLASSES = 100\n",
    "    DATASET_NAME = \"wlasl100_v2\" if VERSION == \"v2\" else \"wlasl100\"\n",
    "elif DATASET_TYPE == \"wlasl300\":\n",
    "    NUM_CLASSES = 300\n",
    "    DATASET_NAME = \"wlasl300_v2\" if VERSION == \"v2\" else \"wlasl300\"\n",
    "else:\n",
    "    raise ValueError(\"DATASET_TYPE debe ser 'wlasl100' o 'wlasl300'\")\n",
    "\n",
    "# Configuraci√≥n de hiperpar√°metros basada en versi√≥n\n",
    "if VERSION == \"v1\":\n",
    "    CONFIG = {\n",
    "        \"model_name\": \"MCG-NJU/videomae-base-finetuned-kinetics\",\n",
    "        \"num_classes\": NUM_CLASSES,\n",
    "        \"batch_size\": 16,\n",
    "        \"max_epochs\": 30,\n",
    "        \"lr\": 1e-4,\n",
    "        \"weight_decay\": 0.05,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"class_weighted\": True,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"min_lr\": 1e-6,\n",
    "        \"patience\": 5,\n",
    "        \"gradient_clip\": 1.0,\n",
    "        \"num_workers\": 2,\n",
    "        \"save_every\": 5,\n",
    "    }\n",
    "elif VERSION == \"v2\":\n",
    "    CONFIG = {\n",
    "        \"model_name\": \"MCG-NJU/videomae-base-finetuned-kinetics\",\n",
    "        \"num_classes\": NUM_CLASSES,\n",
    "        \"batch_size\": 6,\n",
    "        \"max_epochs\": 30,\n",
    "        \"lr\": 1e-5,\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"label_smoothing\": 0.0,\n",
    "        \"class_weighted\": False,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"min_lr\": 1e-6,\n",
    "        \"patience\": 10,\n",
    "        \"gradient_clip\": 1.0,\n",
    "        \"num_workers\": 2,\n",
    "        \"save_every\": 5,\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(\"VERSION debe ser 'v1' o 'v2'\")\n",
    "\n",
    "# Configuraci√≥n de rutas\n",
    "CONFIG.update({\n",
    "    \"dataset_name\": DATASET_NAME,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"data_root\": f\"{DRIVE_ROOT}/data/{DATASET_NAME}\",\n",
    "    \"checkpoint_dir\": f\"{DRIVE_ROOT}/models/{VERSION}/{DATASET_NAME}/checkpoints\",\n",
    "    \"logs_dir\": f\"{DRIVE_ROOT}/runs/{VERSION}/{DATASET_NAME}\",\n",
    "    \"results_dir\": f\"{DRIVE_ROOT}/results/{VERSION}/{DATASET_NAME}\",\n",
    "})\n",
    "\n",
    "# Crear directorios\n",
    "for key in [\"checkpoint_dir\", \"logs_dir\", \"results_dir\"]:\n",
    "    os.makedirs(CONFIG[key], exist_ok=True)\n",
    "\n",
    "# Mostrar configuraci√≥n\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"{'CONFIGURACI√ìN DEL EXPERIMENTO':^70}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Dataset: {DATASET_TYPE.upper()} ({NUM_CLASSES} clases)\")\n",
    "print(f\"Versi√≥n: {VERSION.upper()}\")\n",
    "print(f\"Dataset Name: {DATASET_NAME}\")\n",
    "print(f\"\\nHiperpar√°metros:\")\n",
    "print(f\"  - Batch Size: {CONFIG['batch_size']}\")\n",
    "print(f\"  - Learning Rate: {CONFIG['lr']:.2e}\")\n",
    "print(f\"  - Weight Decay: {CONFIG['weight_decay']}\")\n",
    "print(f\"  - Label Smoothing: {CONFIG['label_smoothing']}\")\n",
    "print(f\"  - Class Weighted: {CONFIG['class_weighted']}\")\n",
    "print(f\"  - Patience: {CONFIG['patience']}\")\n",
    "print(f\"  - Max Epochs: {CONFIG['max_epochs']}\")\n",
    "print(f\"\\nRutas:\")\n",
    "print(f\"  - Data: {CONFIG['data_root']}\")\n",
    "print(f\"  - Checkpoints: {CONFIG['checkpoint_dir']}\")\n",
    "print(f\"  - Logs: {CONFIG['logs_dir']}\")\n",
    "print(f\"  - Results: {CONFIG['results_dir']}\")\n",
    "print(f\"\\nDevice: {CONFIG['device']}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Guardar configuraci√≥n\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "config_path = f\"{CONFIG['results_dir']}/config_{timestamp}.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "print(f\"‚úÖ Configuraci√≥n guardada en: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_prep"
   },
   "source": [
    "# 3Ô∏è‚É£ Preparaci√≥n del Dataset\n",
    "\n",
    "## 3.1 Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_class"
   },
   "outputs": [],
   "source": [
    "NUM_FRAMES = 16\n",
    "\n",
    "# ============================================================\n",
    "#   Cargar mapas de labels\n",
    "# ============================================================\n",
    "def load_label_maps(meta_json: str, subset_json: str):\n",
    "    \"\"\"\n",
    "    Carga los mapeos de video_id a clase.\n",
    "    \"\"\"\n",
    "    with open(subset_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        subset = json.load(f)\n",
    "\n",
    "    vid2label = {}\n",
    "    label_set = set()\n",
    "\n",
    "    for vid, info in subset.items():\n",
    "        label = info[\"action\"][0]\n",
    "        vid2label[vid] = label\n",
    "        label_set.add(label)\n",
    "\n",
    "    labels_sorted = sorted(label_set)\n",
    "    label2id = {lab: lab for lab in labels_sorted}\n",
    "    id2label = {lab: lab for lab in labels_sorted}\n",
    "\n",
    "    return vid2label, label2id, id2label\n",
    "\n",
    "\n",
    "def load_split_list(split_txt: str):\n",
    "    \"\"\"Carga lista de archivos del split.\"\"\"\n",
    "    with open(split_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "\n",
    "def sample_frames_uniform(video_path: str, num_frames: int = NUM_FRAMES):\n",
    "    \"\"\"Extrae frames uniformemente espaciados del video.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if frame_count <= 0:\n",
    "        cap.release()\n",
    "        raise RuntimeError(f\"Video vac√≠o o corrupto: {video_path}\")\n",
    "\n",
    "    indices = np.linspace(0, frame_count - 1, num_frames).astype(int)\n",
    "\n",
    "    frames = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            continue\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        raise RuntimeError(f\"No se pudieron leer frames de {video_path}\")\n",
    "\n",
    "    # Si faltan frames, duplicar el √∫ltimo\n",
    "    while len(frames) < num_frames:\n",
    "        frames.append(frames[-1])\n",
    "\n",
    "    return frames[:num_frames]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#   Clase principal Dataset\n",
    "# ============================================================\n",
    "class WLASLVideoDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        split: str,\n",
    "        base_path: str,\n",
    "        videos_folder: str = \"dataset\",\n",
    "        meta_json: str = \"WLASL_v0.3.json\",\n",
    "        subset_json: str = \"nslt_100.json\",\n",
    "        dataset_size: int = 100,\n",
    "    ):\n",
    "        assert split in [\"train\", \"val\", \"test\"]\n",
    "        self.split = split\n",
    "        self.dataset_size = dataset_size\n",
    "\n",
    "        # Auto-detectar dataset_size\n",
    "        if dataset_size == 100 and \"300\" in base_path:\n",
    "            self.dataset_size = 300\n",
    "        elif dataset_size == 300 and \"100\" in base_path:\n",
    "            self.dataset_size = 100\n",
    "\n",
    "        # Ajustar nombres de archivos JSON\n",
    "        if self.dataset_size == 300:\n",
    "            if meta_json == \"WLASL_v0.3.json\":\n",
    "                meta_json = \"WLASL_v0.3_300.json\"\n",
    "            if subset_json == \"nslt_100.json\":\n",
    "                subset_json = \"nslt_300.json\"\n",
    "\n",
    "        # Rutas\n",
    "        self.base = base_path\n",
    "        self.videos_dir = os.path.join(base_path, videos_folder, split)\n",
    "        self.splits_dir = os.path.join(base_path, \"splits\")\n",
    "        self.meta_json = os.path.join(base_path, meta_json)\n",
    "        self.subset_json = os.path.join(base_path, subset_json)\n",
    "\n",
    "        # Cargar mapas de labels\n",
    "        self.vid2label, self.label2id, self.id2label = load_label_maps(\n",
    "            self.meta_json, self.subset_json\n",
    "        )\n",
    "\n",
    "        # Cargar lista de videos corruptos (opcional)\n",
    "        corrupt_list_path = os.path.join(self.base, f\"corrupt_videos_{split}.txt\")\n",
    "        self.corrupt_set = set()\n",
    "        if os.path.exists(corrupt_list_path):\n",
    "            with open(corrupt_list_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                self.corrupt_set = {line.strip() for line in f if line.strip()}\n",
    "\n",
    "        # Cargar lista de videos del split\n",
    "        split_txt_path = os.path.join(self.splits_dir, f\"{split}_split.txt\")\n",
    "        file_list = load_split_list(split_txt_path)\n",
    "\n",
    "        # Construir lista de muestras\n",
    "        self.samples = []\n",
    "        for raw_fname in file_list:\n",
    "            norm = raw_fname.replace(\"\\\\\", \"/\")\n",
    "            basename = os.path.basename(norm)\n",
    "\n",
    "            if not basename.endswith(\".mp4\"):\n",
    "                continue\n",
    "\n",
    "            if basename in self.corrupt_set:\n",
    "                continue\n",
    "\n",
    "            vid = os.path.splitext(basename)[0]\n",
    "            video_path = os.path.join(self.videos_dir, basename)\n",
    "\n",
    "            if os.path.exists(video_path) and vid in self.vid2label:\n",
    "                label = self.vid2label[vid]\n",
    "                self.samples.append((video_path, label))\n",
    "\n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(f\"No se encontraron muestras para split={split}\")\n",
    "\n",
    "        # Transforms\n",
    "        if split == \"train\":\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [label for _, label in self.samples]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        for attempt in range(5):\n",
    "            video_path, label = self.samples[idx]\n",
    "\n",
    "            try:\n",
    "                frames = sample_frames_uniform(video_path, NUM_FRAMES)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Video corrupto: {video_path} ({e})\")\n",
    "                idx = (idx + 1) % len(self.samples)\n",
    "                continue\n",
    "\n",
    "            frames_t = [self.transform(f) for f in frames]\n",
    "            video_tensor = torch.stack(frames_t, dim=0)  # (T, C, H, W)\n",
    "\n",
    "            return video_tensor, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        raise RuntimeError(f\"Demasiados videos corruptos seguidos\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Dataset class definida correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_download"
   },
   "source": [
    "## 3.2 Descargar/Verificar Dataset\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANTE:** \n",
    "- Si ya tienes el dataset en tu Drive, ajusta la ruta en `CONFIG['data_root']`\n",
    "- Si no lo tienes, sube los archivos manualmente a Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_data"
   },
   "outputs": [],
   "source": [
    "# Verificar si el dataset existe\n",
    "data_path = CONFIG['data_root']\n",
    "\n",
    "required_files = [\n",
    "    f\"{data_path}/splits/train_split.txt\",\n",
    "    f\"{data_path}/splits/val_split.txt\",\n",
    "    f\"{data_path}/splits/test_split.txt\",\n",
    "]\n",
    "\n",
    "if NUM_CLASSES == 100:\n",
    "    required_files.extend([\n",
    "        f\"{data_path}/nslt_100.json\",\n",
    "        f\"{data_path}/WLASL_v0.3.json\",\n",
    "    ])\n",
    "else:\n",
    "    required_files.extend([\n",
    "        f\"{data_path}/nslt_300.json\",\n",
    "        f\"{data_path}/WLASL_v0.3_300.json\",\n",
    "        f\"{data_path}/gloss_to_id.json\",\n",
    "    ])\n",
    "\n",
    "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"‚ùå Archivos faltantes:\")\n",
    "    for f in missing_files:\n",
    "        print(f\"   - {f}\")\n",
    "    print(f\"\\n‚ö†Ô∏è Por favor, sube el dataset a: {data_path}\")\n",
    "    raise FileNotFoundError(\"Dataset no encontrado\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dataset verificado en: {data_path}\")\n",
    "    \n",
    "    # Mostrar estad√≠sticas\n",
    "    for split_name in [\"train\", \"val\", \"test\"]:\n",
    "        split_file = f\"{data_path}/splits/{split_name}_split.txt\"\n",
    "        with open(split_file) as f:\n",
    "            count = len([l for l in f if l.strip()])\n",
    "        print(f\"  - {split_name.capitalize()}: {count} videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_load"
   },
   "source": [
    "## 3.3 Crear DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataloaders"
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] Creando datasets y dataloaders...\")\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = WLASLVideoDataset(\n",
    "    split=\"train\",\n",
    "    base_path=CONFIG['data_root'],\n",
    "    dataset_size=NUM_CLASSES\n",
    ")\n",
    "\n",
    "val_dataset = WLASLVideoDataset(\n",
    "    split=\"val\",\n",
    "    base_path=CONFIG['data_root'],\n",
    "    dataset_size=NUM_CLASSES\n",
    ")\n",
    "\n",
    "test_dataset = WLASLVideoDataset(\n",
    "    split=\"test\",\n",
    "    base_path=CONFIG['data_root'],\n",
    "    dataset_size=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# Crear dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if CONFIG['device'] == \"cuda\" else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if CONFIG['device'] == \"cuda\" else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if CONFIG['device'] == \"cuda\" else False\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DATASETS CARGADOS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Train:      {len(train_dataset):,} videos ({len(train_loader)} batches)\")\n",
    "print(f\"Validation: {len(val_dataset):,} videos ({len(val_loader)} batches)\")\n",
    "print(f\"Test:       {len(test_dataset):,} videos ({len(test_loader)} batches)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "print(\"‚úÖ DataLoaders creados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "# 4Ô∏è‚É£ Entrenamiento\n",
    "\n",
    "## 4.1 Funciones de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_functions"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#   Funciones auxiliares\n",
    "# ============================================================\n",
    "def compute_class_weights(labels: list, num_classes: int, device: str):\n",
    "    \"\"\"Calcula pesos por clase inversamente proporcional a la frecuencia.\"\"\"\n",
    "    class_counts = Counter(labels)\n",
    "    weights = torch.zeros(num_classes, dtype=torch.float32)\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        count = class_counts.get(class_id, 0)\n",
    "        if count > 0:\n",
    "            weights[class_id] = 1.0 / count\n",
    "        else:\n",
    "            weights[class_id] = 0.0\n",
    "\n",
    "    if weights.sum() > 0:\n",
    "        weights = weights / weights.mean()\n",
    "\n",
    "    return weights.to(device)\n",
    "\n",
    "\n",
    "def calculate_accuracy(outputs: torch.Tensor, labels: torch.Tensor) -> float:\n",
    "    \"\"\"Calcula accuracy dado logits y labels.\"\"\"\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    correct = (predictions == labels).sum().item()\n",
    "    accuracy = 100.0 * correct / labels.size(0)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#   Warmup + Cosine Scheduler\n",
    "# ============================================================\n",
    "class WarmupCosineScheduler:\n",
    "    def __init__(self, optimizer, warmup_steps, total_steps, min_lr=1e-6, last_epoch=-1):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.min_lr = min_lr\n",
    "        self.base_lrs = [group['lr'] for group in optimizer.param_groups]\n",
    "        self.current_step = last_epoch + 1\n",
    "\n",
    "    def step(self):\n",
    "        self.current_step += 1\n",
    "\n",
    "        for param_group, base_lr in zip(self.optimizer.param_groups, self.base_lrs):\n",
    "            if self.current_step < self.warmup_steps:\n",
    "                lr = base_lr * (self.current_step / self.warmup_steps)\n",
    "            else:\n",
    "                progress = (self.current_step - self.warmup_steps) / (self.total_steps - self.warmup_steps)\n",
    "                lr = self.min_lr + (base_lr - self.min_lr) * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def get_last_lr(self):\n",
    "        return [group['lr'] for group in self.optimizer.param_groups]\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            'current_step': self.current_step,\n",
    "            'base_lrs': self.base_lrs,\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.current_step = state_dict['current_step']\n",
    "        self.base_lrs = state_dict['base_lrs']\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#   Entrenamiento de una √©poca\n",
    "# ============================================================\n",
    "def train_one_epoch(\n",
    "    model, dataloader, criterion, optimizer, scheduler, device, epoch, writer, gradient_clip=1.0\n",
    "):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total_batches = len(dataloader)\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch:02d} [TRAIN]\", leave=False)\n",
    "\n",
    "    for batch_idx, (videos, labels) in enumerate(progress_bar):\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(pixel_values=videos)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        batch_acc = calculate_accuracy(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        if gradient_clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_acc += batch_acc\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'acc': f\"{batch_acc:.1f}%\",\n",
    "            'lr': f\"{current_lr:.2e}\"\n",
    "        })\n",
    "\n",
    "        global_step = (epoch - 1) * total_batches + batch_idx\n",
    "        writer.add_scalar('Train/Loss_batch', loss.item(), global_step)\n",
    "        writer.add_scalar('Train/Accuracy_batch', batch_acc, global_step)\n",
    "        writer.add_scalar('Train/Learning_rate', current_lr, global_step)\n",
    "\n",
    "    avg_loss = running_loss / total_batches\n",
    "    avg_acc = running_acc / total_batches\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#   Evaluaci√≥n\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, criterion, device, epoch, split=\"VAL\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total_batches = len(dataloader)\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch:02d} [{split:^5}]\", leave=False)\n",
    "\n",
    "    for videos, labels in progress_bar:\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(pixel_values=videos)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        batch_acc = calculate_accuracy(logits, labels)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_acc += batch_acc\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'acc': f\"{batch_acc:.1f}%\"\n",
    "        })\n",
    "\n",
    "    avg_loss = running_loss / total_batches\n",
    "    avg_acc = running_acc / total_batches\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#   Guardar checkpoint\n",
    "# ============================================================\n",
    "def save_checkpoint(\n",
    "    epoch, model, optimizer, scheduler, train_loss, train_acc,\n",
    "    val_loss, val_acc, checkpoint_dir, is_best=False\n",
    "):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc,\n",
    "    }\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pt\")\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"[CHECKPOINT] Guardado: {checkpoint_path}\")\n",
    "\n",
    "    if is_best:\n",
    "        best_path = os.path.join(checkpoint_dir, \"best_model.pt\")\n",
    "        torch.save(checkpoint, best_path)\n",
    "        print(f\"[BEST MODEL] Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Funciones de entrenamiento definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Inicializar Modelo y Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Inicializando modelo y componentes de entrenamiento...\\n\")\n",
    "\n",
    "# Cargar modelo\n",
    "device = CONFIG['device']\n",
    "model = VideoMAEForVideoClassification.from_pretrained(\n",
    "    CONFIG['model_name'],\n",
    "    num_labels=CONFIG['num_classes'],\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Modelo: {CONFIG['model_name']}\")\n",
    "print(f\"Par√°metros totales: {total_params:,}\")\n",
    "print(f\"Par√°metros entrenables: {trainable_params:,}\\n\")\n",
    "\n",
    "# Class weights (si est√° activado)\n",
    "class_weights = None\n",
    "if CONFIG['class_weighted']:\n",
    "    print(\"[INFO] Calculando class weights...\")\n",
    "    train_labels = train_dataset.get_labels()\n",
    "    class_weights = compute_class_weights(train_labels, CONFIG['num_classes'], device)\n",
    "    print(f\"Class weights (min={class_weights.min():.3f}, max={class_weights.max():.3f})\\n\")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=class_weights,\n",
    "    label_smoothing=CONFIG['label_smoothing']\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['lr'],\n",
    "    weight_decay=CONFIG['weight_decay'],\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "total_steps = len(train_loader) * CONFIG['max_epochs']\n",
    "warmup_steps = int(total_steps * CONFIG['warmup_ratio'])\n",
    "\n",
    "scheduler = WarmupCosineScheduler(\n",
    "    optimizer,\n",
    "    warmup_steps=warmup_steps,\n",
    "    total_steps=total_steps,\n",
    "    min_lr=CONFIG['min_lr']\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: AdamW (lr={CONFIG['lr']:.2e}, wd={CONFIG['weight_decay']})\")\n",
    "print(f\"Scheduler: Warmup + Cosine Decay\")\n",
    "print(f\"Total steps: {total_steps}\")\n",
    "print(f\"Warmup steps: {warmup_steps}\\n\")\n",
    "\n",
    "# TensorBoard writer\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = f\"{CONFIG['logs_dir']}/run_{timestamp}\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "print(f\"‚úÖ TensorBoard logs: {log_dir}\")\n",
    "print(f\"‚úÖ Modelo y componentes inicializados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Loop de Entrenamiento Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"{'INICIO DEL ENTRENAMIENTO':^70}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Variables de control\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "epochs_without_improve = 0\n",
    "training_history = []\n",
    "\n",
    "# Directorio de checkpoints para este run\n",
    "run_checkpoint_dir = f\"{CONFIG['checkpoint_dir']}/run_{timestamp}\"\n",
    "os.makedirs(run_checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Guardar configuraci√≥n del run\n",
    "run_config_path = f\"{run_checkpoint_dir}/config.json\"\n",
    "with open(run_config_path, 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, CONFIG['max_epochs'] + 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"EPOCH {epoch}/{CONFIG['max_epochs']}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        # Entrenamiento\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model=model,\n",
    "            dataloader=train_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "            writer=writer,\n",
    "            gradient_clip=CONFIG['gradient_clip']\n",
    "        )\n",
    "\n",
    "        # Validaci√≥n\n",
    "        val_loss, val_acc = evaluate(\n",
    "            model=model,\n",
    "            dataloader=val_loader,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "            split=\"VAL\"\n",
    "        )\n",
    "\n",
    "        # Logging\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"RESULTADOS EPOCH {epoch}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "        print(f\"LR actual:  {current_lr:.2e}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "        # TensorBoard logging por √©poca\n",
    "        writer.add_scalar('Train/Loss_epoch', train_loss, epoch)\n",
    "        writer.add_scalar('Train/Accuracy_epoch', train_acc, epoch)\n",
    "        writer.add_scalar('Val/Loss_epoch', val_loss, epoch)\n",
    "        writer.add_scalar('Val/Accuracy_epoch', val_acc, epoch)\n",
    "\n",
    "        # Guardar historial\n",
    "        training_history.append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'lr': current_lr\n",
    "        })\n",
    "\n",
    "        # Early stopping y checkpoints\n",
    "        is_best = val_loss < best_val_loss\n",
    "\n",
    "        if is_best:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_acc = val_acc\n",
    "            epochs_without_improve = 0\n",
    "        else:\n",
    "            epochs_without_improve += 1\n",
    "\n",
    "        # Guardar checkpoint\n",
    "        if epoch % CONFIG['save_every'] == 0 or is_best or epoch == CONFIG['max_epochs']:\n",
    "            save_checkpoint(\n",
    "                epoch=epoch,\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                train_loss=train_loss,\n",
    "                train_acc=train_acc,\n",
    "                val_loss=val_loss,\n",
    "                val_acc=val_acc,\n",
    "                checkpoint_dir=run_checkpoint_dir,\n",
    "                is_best=is_best\n",
    "            )\n",
    "\n",
    "        # Early stopping\n",
    "        if epochs_without_improve >= CONFIG['patience']:\n",
    "            print(f\"\\n[EARLY STOP] No mejora durante {CONFIG['patience']} epochs\")\n",
    "            print(f\"[EARLY STOP] Deteniendo en epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n[INTERRUPTED] Entrenamiento interrumpido por el usuario\")\n",
    "    # Guardar checkpoint actual\n",
    "    save_checkpoint(\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        train_loss=train_loss,\n",
    "        train_acc=train_acc,\n",
    "        val_loss=val_loss,\n",
    "        val_acc=val_acc,\n",
    "        checkpoint_dir=run_checkpoint_dir,\n",
    "        is_best=False\n",
    "    )\n",
    "\n",
    "# Cerrar writer\n",
    "writer.close()\n",
    "\n",
    "# Guardar historial de entrenamiento\n",
    "history_df = pd.DataFrame(training_history)\n",
    "history_path = f\"{run_checkpoint_dir}/training_history.csv\"\n",
    "history_df.to_csv(history_path, index=False)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"{'ENTRENAMIENTO COMPLETADO':^70}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Mejor Val Loss: {best_val_loss:.4f}\")\n",
    "print(f\"Mejor Val Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"Checkpoints: {run_checkpoint_dir}\")\n",
    "print(f\"Logs: {log_dir}\")\n",
    "print(f\"Historial: {history_path}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Visualizar Curvas de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer historial\n",
    "history_df = pd.read_csv(history_path)\n",
    "\n",
    "# Crear figura con subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history_df['epoch'], history_df['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history_df['epoch'], history_df['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history_df['epoch'], history_df['train_acc'], label='Train Acc', marker='o')\n",
    "axes[1].plot(history_df['epoch'], history_df['val_acc'], label='Val Acc', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Training & Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[2].plot(history_df['epoch'], history_df['lr'], label='Learning Rate', marker='o', color='green')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Learning Rate')\n",
    "axes[2].set_title('Learning Rate Schedule')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar\n",
    "curves_path = f\"{CONFIG['results_dir']}/training_curves_{timestamp}.png\"\n",
    "plt.savefig(curves_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Curvas guardadas en: {curves_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
