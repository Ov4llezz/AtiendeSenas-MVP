{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì VideoMAE - Sign Language Recognition (WLASL)\n",
    "## Clean Training & Evaluation Pipeline\n",
    "\n",
    "**Autor:** Rafael Ovalle - Tesis UNAB  \n",
    "**Dataset:** WLASL100/WLASL300  \n",
    "**Modelo:** VideoMAE\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Configuraciones Disponibles:\n",
    "\n",
    "| Config | Dataset | Train | Val | Test | Batch | LR | Uso |\n",
    "|--------|---------|-------|-----|------|-------|----|-----|\n",
    "| **V1-100** | 100 clases | 807 | 194 | 117 | 16 | 1e-4 | Baseline |\n",
    "| **V2-100** | 100 clases | 1,001 | 117 | 117 | 6 | 1e-5 | Maximizar datos |\n",
    "| **V1-300** | 300 clases | 1,959 | 557 | 271 | 16 | 1e-4 | Baseline |\n",
    "| **V2-300** | 300 clases | 2,516 | 271 | 271 | 6 | 1e-5 | Maximizar datos |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive/TESIS_WLASL\"\n",
    "print(f\"‚úÖ Drive montado: {DRIVE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonar repositorio (si es necesario)\n",
    "import os\n",
    "if not os.path.exists('AtiendeSenas-MVP'):\n",
    "    !git clone https://github.com/Ov4llezz/AtiendeSenas-MVP.git\n",
    "    %cd AtiendeSenas-MVP\n",
    "else:\n",
    "    %cd AtiendeSenas-MVP\n",
    "    !git pull\n",
    "\n",
    "print(\"‚úÖ Repositorio listo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias\n",
    "from colab_utils.config import setup_environment\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ Configuraci√≥n del Experimento\n",
    "\n",
    "**üéØ Configura tu experimento aqu√≠:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colab_utils.config import create_config, print_config, save_config\n",
    "\n",
    "# ============================================================\n",
    "#   CONFIGURA TU EXPERIMENTO AQU√ç\n",
    "# ============================================================\n",
    "DATASET_TYPE = \"wlasl100\"  # \"wlasl100\" o \"wlasl300\"\n",
    "VERSION = \"v1\"             # \"v1\" (baseline) o \"v2\" (experimental)\n",
    "# ============================================================\n",
    "\n",
    "# Crear configuraci√≥n\n",
    "config = create_config(\n",
    "    dataset_type=DATASET_TYPE,\n",
    "    version=VERSION,\n",
    "    drive_root=DRIVE_ROOT\n",
    ")\n",
    "\n",
    "# Mostrar configuraci√≥n\n",
    "print_config(config)\n",
    "\n",
    "# Guardar configuraci√≥n\n",
    "save_config(config, config['results_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ Cargar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from colab_utils.dataset import WLASLVideoDataset\n",
    "\n",
    "print(\"[INFO] Cargando datasets...\\n\")\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = WLASLVideoDataset(\n",
    "    split=\"train\",\n",
    "    base_path=config['data_root'],\n",
    "    dataset_size=config['num_classes']\n",
    ")\n",
    "\n",
    "val_dataset = WLASLVideoDataset(\n",
    "    split=\"val\",\n",
    "    base_path=config['data_root'],\n",
    "    dataset_size=config['num_classes']\n",
    ")\n",
    "\n",
    "test_dataset = WLASLVideoDataset(\n",
    "    split=\"test\",\n",
    "    base_path=config['data_root'],\n",
    "    dataset_size=config['num_classes']\n",
    ")\n",
    "\n",
    "# Crear dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=True if config['device'] == \"cuda\" else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=True if config['device'] == \"cuda\" else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=True if config['device'] == \"cuda\" else False\n",
    ")\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"DATASETS CARGADOS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Train:      {len(train_dataset):,} videos ({len(train_loader)} batches)\")\n",
    "print(f\"Validation: {len(val_dataset):,} videos ({len(val_loader)} batches)\")\n",
    "print(f\"Test:       {len(test_dataset):,} videos ({len(test_loader)} batches)\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colab_utils.training import train_model\n",
    "\n",
    "# Entrenar modelo\n",
    "model, training_history, run_checkpoint_dir, log_dir = train_model(\n",
    "    config=config,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Entrenamiento completado!\")\n",
    "print(f\"Checkpoints: {run_checkpoint_dir}\")\n",
    "print(f\"Logs: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5Ô∏è‚É£ Visualizar Curvas de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from colab_utils.visualization import plot_training_curves\n",
    "\n",
    "# Leer historial\n",
    "history_df = pd.DataFrame(training_history)\n",
    "\n",
    "# Graficar curvas\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "curves_path = f\"{config['results_dir']}/training_curves_{timestamp}.png\"\n",
    "\n",
    "plot_training_curves(history_df, save_path=curves_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6Ô∏è‚É£ Evaluaci√≥n en Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colab_utils.evaluation import evaluate_detailed, print_results, print_top_classes\n",
    "\n",
    "# Cargar mejor modelo\n",
    "print(\"[INFO] Cargando mejor modelo...\\n\")\n",
    "best_model_path = f\"{run_checkpoint_dir}/best_model.pt\"\n",
    "checkpoint = torch.load(best_model_path, map_location=config['device'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Modelo cargado (Epoch {checkpoint['epoch']}, Val Acc: {checkpoint['val_acc']:.2f}%)\\n\")\n",
    "\n",
    "# Evaluar en test set\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'EVALUACI√ìN EN TEST SET':^70}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "test_results = evaluate_detailed(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    device=config['device'],\n",
    "    num_classes=config['num_classes']\n",
    ")\n",
    "\n",
    "# Mostrar resultados\n",
    "print_results(test_results)\n",
    "print_top_classes(test_results, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7Ô∏è‚É£ Visualizaciones Completas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colab_utils.visualization import visualize_all_results\n",
    "\n",
    "# Generar todas las visualizaciones\n",
    "viz_paths = visualize_all_results(\n",
    "    results=test_results,\n",
    "    history_df=history_df,\n",
    "    output_dir=config['results_dir'],\n",
    "    timestamp=timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8Ô∏è‚É£ Guardar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colab_utils.evaluation import save_results\n",
    "\n",
    "# Preparar info del checkpoint\n",
    "checkpoint_info = {\n",
    "    'best_epoch': int(checkpoint['epoch']),\n",
    "    'best_val_loss': float(checkpoint['val_loss']),\n",
    "    'best_val_acc': float(checkpoint['val_acc']),\n",
    "    'total_epochs_trained': len(training_history),\n",
    "}\n",
    "\n",
    "# Guardar resultados\n",
    "json_path, txt_path, pred_path, ts = save_results(\n",
    "    results=test_results,\n",
    "    config=config,\n",
    "    checkpoint_info=checkpoint_info,\n",
    "    output_dir=config['results_dir']\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"{'ARCHIVOS GENERADOS':^80}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Checkpoints:      {run_checkpoint_dir}\")\n",
    "print(f\"Logs TensorBoard: {log_dir}\")\n",
    "print(f\"JSON completo:    {json_path}\")\n",
    "print(f\"Reporte TXT:      {txt_path}\")\n",
    "print(f\"Predicciones:     {pred_path}\")\n",
    "print(f\"Visualizaciones:  {config['results_dir']}\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9Ô∏è‚É£ TensorBoard (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar extensi√≥n TensorBoard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Lanzar TensorBoard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîü Descargar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprimir todos los resultados\n",
    "!zip -r results_{timestamp}.zip \\\n",
    "    {config['results_dir']} \\\n",
    "    {run_checkpoint_dir} \\\n",
    "    {log_dir}\n",
    "\n",
    "# Descargar\n",
    "from google.colab import files\n",
    "files.download(f'results_{timestamp}.zip')\n",
    "\n",
    "print(\"\\n‚úÖ ¬°Resultados descargados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ ¬°Experimento Completado!\n",
    "\n",
    "### üìä Resumen:\n",
    "- **Dataset:** {config['dataset_type'].upper()}\n",
    "- **Versi√≥n:** {config['version'].upper()}\n",
    "- **Test Accuracy:** Ver resultados arriba\n",
    "- **Todos los archivos guardados en Google Drive**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
