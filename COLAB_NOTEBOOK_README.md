# ğŸ““ GuÃ­a Completa del Notebook de Google Colab

## ğŸ¯ VideoMAE WLASL - Training & Evaluation Complete Pipeline

Este notebook proporciona un pipeline completo para entrenar y evaluar modelos VideoMAE en los datasets WLASL100/WLASL300 para reconocimiento de lengua de seÃ±as.

---

## ğŸ“ Archivos Generados

### 1. **VideoMAE_WLASL_Training_Complete.ipynb**
- Notebook principal para Google Colab
- Secciones 1-4: Setup, configuraciÃ³n, preparaciÃ³n de datos y entrenamiento

### 2. **VideoMAE_Evaluation_Section.txt**
- Secciones 5-8: EvaluaciÃ³n completa, visualizaciones y exportaciÃ³n
- Copiar y pegar estas celdas al final del notebook principal

---

## ğŸš€ CÃ³mo Usar el Notebook

### **Paso 1: Preparar Datos en Google Drive**

1. Sube tu dataset WLASL a Google Drive en la siguiente estructura:

```
MyDrive/
â””â”€â”€ TESIS_WLASL/
    â””â”€â”€ data/
        â”œâ”€â”€ wlasl100/          # Dataset WLASL100 V1
        â”‚   â”œâ”€â”€ splits/
        â”‚   â”‚   â”œâ”€â”€ train_split.txt
        â”‚   â”‚   â”œâ”€â”€ val_split.txt
        â”‚   â”‚   â””â”€â”€ test_split.txt
        â”‚   â”œâ”€â”€ dataset/
        â”‚   â”‚   â”œâ”€â”€ train/     # Videos de entrenamiento
        â”‚   â”‚   â”œâ”€â”€ val/       # Videos de validaciÃ³n
        â”‚   â”‚   â””â”€â”€ test/      # Videos de test
        â”‚   â”œâ”€â”€ nslt_100.json
        â”‚   â””â”€â”€ WLASL_v0.3.json
        â”‚
        â”œâ”€â”€ wlasl100_v2/       # Dataset WLASL100 V2 (opcional)
        â”œâ”€â”€ wlasl300/          # Dataset WLASL300 V1 (opcional)
        â””â”€â”€ wlasl300_v2/       # Dataset WLASL300 V2 (opcional)
```

### **Paso 2: Abrir el Notebook en Colab**

1. Sube `VideoMAE_WLASL_Training_Complete.ipynb` a Google Drive
2. Abre con Google Colab
3. AsegÃºrate de tener GPU activada:
   - **Runtime** â†’ **Change runtime type** â†’ **GPU** (T4, V100, o A100)

### **Paso 3: Agregar SecciÃ³n de EvaluaciÃ³n**

1. Abre `VideoMAE_Evaluation_Section.txt`
2. Copia todo el contenido
3. Pega al final del notebook principal creando nuevas celdas
4. Guarda el notebook

### **Paso 4: Configurar Experimento**

En la celda de "ConfiguraciÃ³n del Experimento", ajusta:

```python
# SELECCIONA TU CONFIGURACIÃ“N:
DATASET_TYPE = "wlasl100"  # o "wlasl300"
VERSION = "v1"             # o "v2"
```

**Opciones Disponibles:**

| DATASET_TYPE | VERSION | Description |
|--------------|---------|-------------|
| `"wlasl100"` | `"v1"` | 100 clases, train/val/test separados, regularizaciÃ³n activa |
| `"wlasl100"` | `"v2"` | 100 clases, train+val combinados, sin regularizaciÃ³n |
| `"wlasl300"` | `"v1"` | 300 clases, train/val/test separados, regularizaciÃ³n activa |
| `"wlasl300"` | `"v2"` | 300 clases, train+val combinados, sin regularizaciÃ³n |

### **Paso 5: Ejecutar el Notebook**

1. **Ejecutar todas las celdas:** Runtime â†’ Run all
2. **Montar Google Drive** cuando se solicite
3. **Monitorear progreso:**
   - Barras de progreso en cada epoch
   - MÃ©tricas en tiempo real
   - TensorBoard (opcional)

---

## ğŸ“Š Resultados Generados

### **Archivos AutomÃ¡ticos:**

Todos los resultados se guardan en `MyDrive/TESIS_WLASL/`:

#### **1. Checkpoints del Modelo** (`models/{version}/{dataset}/checkpoints/run_{timestamp}/`)
- `best_model.pt` - Mejor modelo basado en val loss
- `checkpoint_epoch_X.pt` - Checkpoints cada N epochs
- `config.json` - ConfiguraciÃ³n del entrenamiento

#### **2. Logs de TensorBoard** (`runs/{version}/{dataset}/run_{timestamp}/`)
- Loss y accuracy por batch y epoch
- Learning rate schedule
- Visualizaciones en tiempo real

#### **3. Resultados de EvaluaciÃ³n** (`results/{version}/{dataset}/`)
- `complete_results_{timestamp}.json` - Todas las mÃ©tricas en JSON
- `report_{timestamp}.txt` - Reporte legible
- `predictions_{timestamp}.csv` - Predicciones detalladas
- `training_history.csv` - Historial de entrenamiento

#### **4. Visualizaciones** (`results/{version}/{dataset}/`)
- `training_curves_{timestamp}.png` - Loss, accuracy y LR
- `confusion_matrix_{timestamp}.png` - Matriz de confusiÃ³n
- `class_performance_{timestamp}.png` - Mejores y peores clases
- `accuracy_distribution_{timestamp}.png` - DistribuciÃ³n de accuracy
- `support_analysis_{timestamp}.png` - AnÃ¡lisis por nÃºmero de muestras

---

## ğŸ“ˆ MÃ©tricas Incluidas

### **MÃ©tricas Generales:**
- âœ… **Accuracy Total**
- âœ… **Precision** (Macro y Weighted)
- âœ… **Recall** (Macro y Weighted)
- âœ… **F1-Score** (Macro y Weighted)
- âœ… **Top-K Accuracy** (K=1, 3, 5)

### **MÃ©tricas Por Clase:**
- âœ… Accuracy por clase
- âœ… Precision por clase
- âœ… Recall por clase
- âœ… F1-Score por clase
- âœ… Support (nÃºmero de muestras) por clase

### **AnÃ¡lisis Adicionales:**
- âœ… Top 10 mejores clases
- âœ… Top 10 peores clases
- âœ… EstadÃ­sticas descriptivas (media, mediana, std, min, max)
- âœ… AnÃ¡lisis por umbral de support
- âœ… Matriz de confusiÃ³n normalizada
- âœ… Curvas de entrenamiento

---

## âš™ï¸ Configuraciones de HiperparÃ¡metros

### **V1 (Baseline):**
```python
{
    "batch_size": 16,
    "lr": 1e-4,
    "weight_decay": 0.05,
    "label_smoothing": 0.1,
    "class_weighted": True,
    "patience": 5,
    "max_epochs": 30
}
```

**Uso:** ExperimentaciÃ³n, tuning, validaciÃ³n cientÃ­fica

### **V2 (Experimental):**
```python
{
    "batch_size": 6,
    "lr": 1e-5,
    "weight_decay": 0.0,
    "label_smoothing": 0.0,
    "class_weighted": False,
    "patience": 10,
    "max_epochs": 30
}
```

**Uso:** Modelo final con mÃ¡ximos datos

---

## ğŸ”§ PersonalizaciÃ³n Avanzada

### **Modificar HiperparÃ¡metros:**

DespuÃ©s de la celda de configuraciÃ³n, puedes sobrescribir valores:

```python
# Personalizar despuÃ©s de la configuraciÃ³n automÃ¡tica
CONFIG['batch_size'] = 8
CONFIG['max_epochs'] = 50
CONFIG['lr'] = 5e-5
CONFIG['patience'] = 15
```

### **Agregar Data Augmentation Personalizado:**

En la clase `WLASLVideoDataset`, modifica el transform de train:

```python
if split == "train":
    self.transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),  # MÃ¡s agresivo
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(15),  # Agregar rotaciÃ³n
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
```

### **Cambiar Modelo Base:**

```python
CONFIG['model_name'] = "MCG-NJU/videomae-large-finetuned-kinetics"  # Usar modelo large
```

---

## ğŸ“Š Ver Resultados en TensorBoard

### **OpciÃ³n 1: Directamente en el Notebook**

Ejecuta la celda final:

```python
%load_ext tensorboard
%tensorboard --logdir {CONFIG['logs_dir']}
```

### **OpciÃ³n 2: TensorBoard.dev (Compartir resultados)**

```python
!tensorboard dev upload --logdir {CONFIG['logs_dir']} \
  --name "VideoMAE WLASL100 V1" \
  --description "Baseline experiment"
```

---

## ğŸ’¾ Descargar Resultados

### **Descargar Todo:**

```python
# Comprimir resultados
!zip -r results_{timestamp}.zip \
    {CONFIG['results_dir']} \
    {run_checkpoint_dir} \
    {log_dir}

# Descargar
from google.colab import files
files.download(f'results_{timestamp}.zip')
```

### **Descargar Solo Mejor Modelo:**

```python
from google.colab import files
files.download(f"{run_checkpoint_dir}/best_model.pt")
```

---

## ğŸ› Troubleshooting

### **Error: "Dataset no encontrado"**
- Verifica que la ruta en `CONFIG['data_root']` sea correcta
- AsegÃºrate de haber montado Google Drive
- Verifica que los archivos de splits existan

### **Error: "CUDA out of memory"**
- Reduce `batch_size` (ej: 4, 2)
- Reduce `num_workers` (ej: 0, 1)
- Usa GPU con mÃ¡s memoria (V100 o A100)

### **Error: Videos corruptos**
- El dataset automÃ¡ticamente salta videos corruptos
- Verifica `corrupt_videos_{split}.txt` si existe

### **Entrenamiento muy lento**
- Verifica que estÃ©s usando GPU: `print(CONFIG['device'])`
- Reduce `num_workers` si hay cuellos de botella en I/O
- Considera usar un batch_size mayor si la memoria lo permite

---

## ğŸ“ Ejemplo de Flujo Completo

```python
# 1. Configurar
DATASET_TYPE = "wlasl100"
VERSION = "v1"

# 2. Ejecutar todas las celdas
# Runtime â†’ Run all

# 3. Esperar entrenamiento (30-60 min con T4)

# 4. Revisar resultados:
print(f"Test Accuracy: {metrics['total_accuracy']:.2f}%")
print(f"Top-3 Accuracy: {metrics['top_k']['top_3']:.2f}%")

# 5. Descargar modelo
from google.colab import files
files.download(f"{run_checkpoint_dir}/best_model.pt")

# 6. Descargar todos los resultados
!zip -r my_results.zip {CONFIG['results_dir']} {run_checkpoint_dir}
files.download('my_results.zip')
```

---

## ğŸ“š Para tu Tesis

### **Secciones Recomendadas:**

1. **MetodologÃ­a:**
   - ConfiguraciÃ³n de hiperparÃ¡metros (SecciÃ³n 2.1)
   - Arquitectura del modelo (VideoMAE)
   - Data augmentation aplicado

2. **Resultados:**
   - Tabla de mÃ©tricas generales (SecciÃ³n 5.3)
   - GrÃ¡ficos de curvas de entrenamiento (SecciÃ³n 4.4)
   - Matriz de confusiÃ³n (SecciÃ³n 6.1)
   - AnÃ¡lisis por clase (Secciones 5.4, 5.5)

3. **DiscusiÃ³n:**
   - ComparaciÃ³n V1 vs V2
   - AnÃ¡lisis de clases difÃ­ciles (peores 10)
   - Impacto del nÃºmero de muestras (SecciÃ³n 6.4)

### **Figuras para Incluir:**
- âœ… `training_curves_{timestamp}.png`
- âœ… `confusion_matrix_{timestamp}.png`
- âœ… `class_performance_{timestamp}.png`
- âœ… `accuracy_distribution_{timestamp}.png`

### **Tablas para Incluir:**
- âœ… MÃ©tricas generales (del reporte TXT)
- âœ… Top-10 mejores y peores clases
- âœ… ComparaciÃ³n V1 vs V2

---

## ğŸ“ Recomendaciones Finales

1. **Siempre guarda tu configuraciÃ³n:** El notebook guarda automÃ¡ticamente `config.json`
2. **Usa nombres descriptivos:** Los timestamps ayudan a organizar experimentos
3. **Documenta cambios:** Si modificas hiperparÃ¡metros, anÃ³talos
4. **Compara resultados:** Ejecuta V1 primero, luego V2
5. **Backup en Drive:** Todo se guarda automÃ¡ticamente en tu Drive

---

**Â¡Ã‰xito con tu tesis!** ğŸ“âœ¨

Si tienes dudas o necesitas modificaciones, revisa la documentaciÃ³n en `EXPERIMENTS_V1_VS_V2.md`.
