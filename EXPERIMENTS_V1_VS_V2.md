# ComparaciÃ³n de Experimentos: V1 vs V2

## ğŸ“‹ Resumen

Este documento describe las diferencias entre las configuraciones V1 (baseline) y V2 (experimental) para el entrenamiento de VideoMAE en WLASL100/300.

---

## ğŸ“Š ConfiguraciÃ³n de Datasets

### **WLASL100 - 100 Clases**

#### **V1 - ConfiguraciÃ³n Original (Baseline)**

| Split | Videos | PropÃ³sito |
|-------|---------|-----------|
| Train | 807 | Entrenamiento |
| Val | 194 | ValidaciÃ³n durante entrenamiento |
| Test | 117 | EvaluaciÃ³n final |
| **Total** | **1,118** | |

**UbicaciÃ³n:** `data/wlasl100/`

**Scripts:** `scripts/`

#### **V2 - ConfiguraciÃ³n Experimental (Train+Val Combinados)**

| Split | Videos | PropÃ³sito |
|-------|---------|-----------|
| Train | 1,001 (807+194) | Entrenamiento (train+val combinados) |
| Val | 117 (test) | ValidaciÃ³n durante entrenamiento |
| Test | 117 (test) | EvaluaciÃ³n final |
| **Total** | **1,118** | |

**UbicaciÃ³n:** `data/wlasl100_v2/`

**Scripts:** `scripts_v2/`

---

### **WLASL300 - 300 Clases**

#### **V1 - ConfiguraciÃ³n Original (Baseline)**

| Split | Videos | PropÃ³sito |
|-------|---------|-----------|
| Train | 1,959 | Entrenamiento |
| Val | 557 | ValidaciÃ³n durante entrenamiento |
| Test | 271 | EvaluaciÃ³n final |
| **Total** | **2,787** | |

**UbicaciÃ³n:** `data/wlasl300/`

**Scripts:** `scripts/`

#### **V2 - ConfiguraciÃ³n Experimental (Train+Val Combinados)**

| Split | Videos | PropÃ³sito |
|-------|---------|-----------|
| Train | 2,516 (1,959+557) | Entrenamiento (train+val combinados) |
| Val | 271 (test) | ValidaciÃ³n durante entrenamiento |
| Test | 271 (test) | EvaluaciÃ³n final |
| **Total** | **2,787** | |

**UbicaciÃ³n:** `data/wlasl300_v2/`

**Scripts:** `scripts_v2/`

---

## âš™ï¸ HiperparÃ¡metros

| ParÃ¡metro | V1 (Baseline) | V2 (Experimental) | Cambio |
|-----------|---------------|-------------------|--------|
| **Batch Size** | 16 | 6 | â¬‡ï¸ Reducido (66% menos) |
| **Max Epochs** | 30 | 30 | = Sin cambio |
| **Learning Rate** | 1e-4 | 1e-5 | â¬‡ï¸ Reducido (10x menor) |
| **Weight Decay** | 0.05 | 0.0 | âŒ Eliminado |
| **Label Smoothing** | 0.1 | 0.0 | âŒ Desactivado |
| **Class Weighted** | True | False | âŒ Desactivado |
| **Patience** | 5 | 10 | â¬†ï¸ Aumentado (2x) |
| **Warmup Ratio** | 0.1 (10%) | 0.1 (10%) | = Sin cambio |
| **Min LR** | 1e-6 | 1e-6 | = Sin cambio |
| **Gradient Clip** | 1.0 | 1.0 | = Sin cambio |

---

## ğŸ¯ Estrategias de Entrenamiento

### **V1 - Baseline**

- âœ… **RegularizaciÃ³n agresiva:**
  - Weight decay: 0.05
  - Label smoothing: 0.1
  - Class weighting activo

- âœ… **Early stopping conservador:**
  - Patience: 5 epochs
  - Basado en validation loss

- âœ… **Batch size estÃ¡ndar:** 16

- âœ… **Learning rate estÃ¡ndar:** 1e-4

### **V2 - Experimental**

- ğŸ”¬ **Sin regularizaciÃ³n explÃ­cita:**
  - Weight decay: 0.0 (confiando en la arquitectura)
  - Label smoothing: 0.0 (confiando en mÃ¡s datos)
  - Class weighting desactivado

- ğŸ”¬ **Early stopping mÃ¡s paciente:**
  - Patience: 10 epochs
  - Permite mÃ¡s tiempo para convergencia

- ğŸ”¬ **Batch size reducido:** 6
  - Mayor nÃºmero de actualizaciones de pesos
  - Posible mejor generalizaciÃ³n

- ğŸ”¬ **Learning rate mÃ¡s bajo:** 1e-5
  - Aprendizaje mÃ¡s fino
  - Complementa mayor cantidad de datos

---

## ğŸ”„ Frame Sampling

**Ambas versiones usan sampling uniforme:**
- MÃ©todo: `np.linspace(0, frame_count-1, 16)`
- 16 frames uniformemente espaciados
- Cubre toda la duraciÃ³n del video

---

## ğŸ§ª HipÃ³tesis y JustificaciÃ³n

### **Â¿Por quÃ© V2?**

**Objetivo:** Maximizar datos de entrenamiento para potencialmente mejorar el desempeÃ±o del modelo.

#### **1. MÃ¡s datos de entrenamiento (807 â†’ 1,001)**
- âœ… **HipÃ³tesis:** MÃ¡s ejemplos â†’ mejor generalizaciÃ³n
- âš ï¸ **Riesgo:** Sin validaciÃ³n independiente â†’ posible overfitting a test set

#### **2. EliminaciÃ³n de regularizaciÃ³n**
- âœ… **HipÃ³tesis:** Con mÃ¡s datos, menos necesidad de regularizaciÃ³n artificial
- ğŸ“Š **Razonamiento:** Class weights y label smoothing son Ãºtiles con datasets pequeÃ±os

#### **3. Batch size reducido (16 â†’ 6)**
- âœ… **HipÃ³tesis:** MÃ¡s actualizaciones de gradientes â†’ mejor optimizaciÃ³n
- ğŸ“Š **Razonamiento:** Con mÃ¡s datos, batch size pequeÃ±o puede ayudar a explorar mejor el espacio

#### **4. Learning rate reducido (1e-4 â†’ 1e-5)**
- âœ… **HipÃ³tesis:** LR bajo + mÃ¡s datos = ajuste mÃ¡s fino
- ğŸ“Š **Razonamiento:** Evita sobrepasar mÃ­nimos locales buenos

#### **5. Patience aumentado (5 â†’ 10)**
- âœ… **HipÃ³tesis:** MÃ¡s datos requieren mÃ¡s tiempo para converger
- ğŸ“Š **Razonamiento:** Evita detener prematuramente el entrenamiento

---

## âš ï¸ Consideraciones Importantes

### **Ventajas de V2:**
- âœ… **24% mÃ¡s datos de entrenamiento** (807 â†’ 1,001)
- âœ… Aprovecha todos los videos disponibles
- âœ… Potencial de mejor generalizaciÃ³n

### **Desventajas de V2:**
- âŒ **No hay validaciÃ³n independiente**
  - El test set se usa para validaciÃ³n durante entrenamiento
  - Viola el principio de "unseen data"
  - Riesgo de overfitting al test set

- âŒ **No se pueden ajustar hiperparÃ¡metros**
  - Cualquier tuning usarÃ­a el test set
  - Los resultados finales pueden estar sesgados

- âŒ **Entrenamiento mÃ¡s lento**
  - Batch size pequeÃ±o â†’ mÃ¡s iteraciones
  - Patience alto â†’ mÃ¡s epochs potenciales

---

## ğŸ“ Estructura de Archivos

```
AtiendeSenas-MVP/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ wlasl100/                    # V1 - Dataset original
â”‚   â”‚   â”œâ”€â”€ splits/
â”‚   â”‚   â”‚   â”œâ”€â”€ train_split.txt      (807 videos)
â”‚   â”‚   â”‚   â”œâ”€â”€ val_split.txt        (194 videos)
â”‚   â”‚   â”‚   â””â”€â”€ test_split.txt       (117 videos)
â”‚   â”‚   â”œâ”€â”€ dataset/                 (videos organizados)
â”‚   â”‚   â”œâ”€â”€ nslt_100.json
â”‚   â”‚   â””â”€â”€ WLASL_v0.3.json
â”‚   â”‚
â”‚   â”œâ”€â”€ wlasl100_v2/                 # V2 - Dataset experimental WLASL100
â”‚   â”‚   â”œâ”€â”€ splits/
â”‚   â”‚   â”‚   â”œâ”€â”€ train_split.txt      (1,001 videos = train+val)
â”‚   â”‚   â”‚   â”œâ”€â”€ val_split.txt        (117 videos = test)
â”‚   â”‚   â”‚   â””â”€â”€ test_split.txt       (117 videos = test)
â”‚   â”‚   â”œâ”€â”€ dataset/ â†’ symlink to wlasl100/dataset/
â”‚   â”‚   â”œâ”€â”€ videos/ â†’ symlink to wlasl100/videos/
â”‚   â”‚   â”œâ”€â”€ nslt_100.json
â”‚   â”‚   â””â”€â”€ WLASL_v0.3.json
â”‚   â”‚
â”‚   â”œâ”€â”€ wlasl300/                    # V1 - Dataset original WLASL300
â”‚   â”‚   â”œâ”€â”€ splits/
â”‚   â”‚   â”‚   â”œâ”€â”€ train_split.txt      (1,959 videos)
â”‚   â”‚   â”‚   â”œâ”€â”€ val_split.txt        (557 videos)
â”‚   â”‚   â”‚   â””â”€â”€ test_split.txt       (271 videos)
â”‚   â”‚   â”œâ”€â”€ dataset/                 (videos organizados)
â”‚   â”‚   â”œâ”€â”€ nslt_300.json
â”‚   â”‚   â”œâ”€â”€ gloss_to_id.json
â”‚   â”‚   â””â”€â”€ WLASL_v0.3_300.json
â”‚   â”‚
â”‚   â””â”€â”€ wlasl300_v2/                 # V2 - Dataset experimental WLASL300
â”‚       â”œâ”€â”€ splits/
â”‚       â”‚   â”œâ”€â”€ train_split.txt      (2,516 videos = train+val)
â”‚       â”‚   â”œâ”€â”€ val_split.txt        (271 videos = test)
â”‚       â”‚   â””â”€â”€ test_split.txt       (271 videos = test)
â”‚       â”œâ”€â”€ dataset/ â†’ symlink to wlasl300/dataset/
â”‚       â”œâ”€â”€ videos/ â†’ symlink to wlasl300/videos/
â”‚       â”œâ”€â”€ nslt_300.json
â”‚       â”œâ”€â”€ gloss_to_id.json
â”‚       â””â”€â”€ WLASL_v0.3_300.json
â”‚
â”œâ”€â”€ scripts/                         # V1 - Scripts originales
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ test.py
â”‚   â””â”€â”€ WLASLDataset.py
â”‚
â”œâ”€â”€ scripts_v2/                      # V2 - Scripts experimentales
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ test.py
â”‚   â””â”€â”€ WLASLDataset.py
â”‚
â”œâ”€â”€ models/                          # V1 - Modelos y checkpoints
â”‚   â””â”€â”€ checkpoints/
â”‚       â””â”€â”€ run_YYYYMMDD_HHMMSS/
â”‚
â”œâ”€â”€ models_v2/                       # V2 - Modelos y checkpoints
â”‚   â””â”€â”€ checkpoints/
â”‚       â””â”€â”€ run_YYYYMMDD_HHMMSS/
â”‚
â”œâ”€â”€ runs/                            # V1 - TensorBoard logs
â”‚   â””â”€â”€ run_YYYYMMDD_HHMMSS/
â”‚
â”œâ”€â”€ runs_v2/                         # V2 - TensorBoard logs
â”‚   â””â”€â”€ run_YYYYMMDD_HHMMSS/
â”‚
â”œâ”€â”€ evaluation_results/              # V1 - Resultados evaluaciÃ³n
â”‚   â”œâ”€â”€ test_results_*.json
â”‚   â”œâ”€â”€ test_results_*.txt
â”‚   â””â”€â”€ *.png
â”‚
â””â”€â”€ evaluation_results_v2/           # V2 - Resultados evaluaciÃ³n
    â”œâ”€â”€ test_results_*.json
    â”œâ”€â”€ test_results_*.txt
    â””â”€â”€ *.png
```

---

## ğŸš€ CÃ³mo Usar

### **Entrenar Modelo V1 (Baseline)**

```bash
# WLASL100 - Desde el directorio raÃ­z del proyecto
cd scripts
python train.py --dataset wlasl100

# WLASL300 - Desde el directorio raÃ­z del proyecto
cd scripts
python train.py --dataset wlasl300
```

### **Entrenar Modelo V2 (Experimental)**

```bash
# WLASL100_V2 - Desde el directorio raÃ­z del proyecto
cd scripts_v2
python train.py --dataset wlasl100_v2

# WLASL300_V2 - Desde el directorio raÃ­z del proyecto
cd scripts_v2
python train.py --dataset wlasl300_v2
```

### **Evaluar Modelo V1**

```bash
cd scripts
python test.py --list-runs              # Ver runs disponibles
python test.py --run-id 1               # Evaluar run especÃ­fico

# Para WLASL300, especificar base_path si es necesario
python test.py --run-id 1 --base_path data/wlasl300
```

### **Evaluar Modelo V2**

```bash
cd scripts_v2
python test.py --list-runs              # Ver runs disponibles V2
python test.py --run-id 1               # Evaluar run especÃ­fico V2

# Para WLASL300_V2, el base_path se detecta automÃ¡ticamente del checkpoint
python test.py --run-id 1
```

---

## ğŸ“ˆ ComparaciÃ³n de Resultados (A completar despuÃ©s del entrenamiento)

| MÃ©trica | V1 (Baseline) | V2 (Experimental) | Diferencia |
|---------|---------------|-------------------|------------|
| **Test Accuracy** | TBD | TBD | TBD |
| **Top-3 Accuracy** | TBD | TBD | TBD |
| **Top-5 Accuracy** | TBD | TBD | TBD |
| **Precision (Macro)** | TBD | TBD | TBD |
| **Recall (Macro)** | TBD | TBD | TBD |
| **F1-Score (Macro)** | TBD | TBD | TBD |
| **Val Loss Final** | TBD | TBD | TBD |
| **Epochs Completados** | TBD | TBD | TBD |
| **Tiempo de Entrenamiento** | TBD | TBD | TBD |

---

## ğŸ“ Recomendaciones

### **CuÃ¡ndo usar V1:**
- âœ… Para experimentar con hiperparÃ¡metros
- âœ… Para validaciÃ³n cientÃ­fica rigurosa
- âœ… Cuando necesitas validaciÃ³n independiente

### **CuÃ¡ndo usar V2:**
- âœ… Como experimento final despuÃ©s de optimizar V1
- âœ… Cuando necesitas maximizar uso de datos disponibles
- âœ… Para comparar impacto de mÃ¡s datos vs regularizaciÃ³n

### **Flujo de trabajo recomendado:**
1. **Fase 1:** Experimentar con V1 para encontrar mejores hiperparÃ¡metros
2. **Fase 2:** Entrenar modelo final con V2 usando configuraciÃ³n optimizada
3. **Fase 3:** Comparar resultados finales entre V1 y V2

---

## ğŸ“ Notas Adicionales

- Ambas configuraciones mantienen los mismos videos (no hay duplicados)
- Los enlaces simbÃ³licos en V2 ahorran espacio en disco
- Los resultados se guardan en carpetas separadas para evitar confusiÃ³n
- El frame sampling es idÃ©ntico en ambas versiones

---

**Fecha de creaciÃ³n:** 2025-01-29

**Autor:** Rafael Ovalle - Tesis UNAB
