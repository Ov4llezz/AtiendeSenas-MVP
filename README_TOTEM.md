# ğŸ¤– TÃ³tem LSCh - Sistema de Reconocimiento de Lengua de SeÃ±as Chilena

Sistema completo de reconocimiento de seÃ±as usando VideoMAE + Chatbot Gemini para orientaciÃ³n en salud pÃºblica.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un tÃ³tem de autoatenciÃ³n que permite a personas Sordas comunicarse mediante videos de seÃ±as. El sistema:

1. Recibe un video de una seÃ±a
2. Detecta la palabra correspondiente con VideoMAE
3. Genera una respuesta empÃ¡tica contextualizada con Gemini
4. Muestra todo en una interfaz minimalista tipo tÃ³tem

## ğŸ—ï¸ Arquitectura

```
AtiendeSenas-MVP/
â”œâ”€â”€ backend/                 # API FastAPI (Python 3.10)
â”‚   â”œâ”€â”€ main.py             # Endpoint principal
â”‚   â”œâ”€â”€ config.py           # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ modules/            # MÃ³dulos separados
â”‚   â”‚   â”œâ”€â”€ video_ingestion.py
â”‚   â”‚   â”œâ”€â”€ video_processing.py
â”‚   â”‚   â”œâ”€â”€ videomae_inference.py
â”‚   â”‚   â”œâ”€â”€ conversation_history.py
â”‚   â”‚   â””â”€â”€ gemini_chatbot.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ frontend/               # React + Vite + TypeScript
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ VideoUploader.tsx
    â”‚   â”‚   â”œâ”€â”€ PredictionDisplay.tsx
    â”‚   â”‚   â”œâ”€â”€ ChatResponseDisplay.tsx
    â”‚   â”‚   â”œâ”€â”€ LatencyPanel.tsx
    â”‚   â”‚   â””â”€â”€ LoadingIndicator.tsx
    â”‚   â”œâ”€â”€ App.tsx
    â”‚   â””â”€â”€ main.tsx
    â””â”€â”€ package.json
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### **Prerequisitos**

- Python 3.10.0
- Node.js 18+ y npm
- GPU recomendada (para inferencia VideoMAE)
- API Key de Google Gemini

### **1. Backend Setup**

```bash
cd backend

# Activar entorno virtual (si no estÃ¡ activo)
source ../venv_backend/Scripts/activate  # Windows Git Bash
# o
../venv_backend/Scripts/activate.bat     # Windows CMD

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env
# Editar .env y agregar tu GEMINI_API_KEY
```

**Archivo `.env` requerido:**

```env
GEMINI_API_KEY=tu_api_key_aqui
MODEL_PATH=../models/v2/wlasl100/checkpoints/run_XXXXXX/best_model.pt
GLOSSES_PATH=../glosas_wlasl100_es.txt
NUM_CLASSES=100
HOST=0.0.0.0
PORT=8000
CORS_ORIGINS=http://localhost:5173
MIN_CONFIDENCE=0.55
```

### **2. Frontend Setup**

```bash
cd frontend

# Instalar dependencias
npm install
```

## â–¶ï¸ EjecuciÃ³n

### **OpciÃ³n 1: Desarrollo (2 terminales)**

**Terminal 1 - Backend:**
```bash
cd backend
python main.py
```

El servidor estarÃ¡ en: `http://localhost:8000`

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
```

El frontend estarÃ¡ en: `http://localhost:5173`

### **OpciÃ³n 2: ProducciÃ³n**

**Backend:**
```bash
cd backend
uvicorn main:app --host 0.0.0.0 --port 8000
```

**Frontend:**
```bash
cd frontend
npm run build
npm run preview
```

## ğŸ“¡ API Endpoints

### **`POST /api/full-pipeline`**

Procesa un video de seÃ±a completo.

**Request:**
- `video`: archivo de video (mp4/mov)
- `history`: (opcional) historial previo

**Response:**
```json
{
  "predicted_word": "PAIN",
  "confidence": 0.87,
  "chatbot_response": "Entiendo que siente dolor. Â¿Puede indicarme dÃ³nde le duele?",
  "history": ["HELLO", "HELP", "PAIN"],
  "latency_ms": {
    "videomae": 450.2,
    "chatbot": 320.5,
    "total": 770.7
  }
}
```

### **Otros Endpoints:**

- `GET /health` - Health check
- `POST /api/reset-history` - Reiniciar historial
- `GET /api/history` - Obtener historial actual

## ğŸ¯ Flujo del Sistema

1. **Usuario:** Sube video de seÃ±a en la interfaz
2. **Backend:**
   - Valida y guarda video temporalmente
   - Extrae 16 frames uniformes
   - Redimensiona a 224x224 y normaliza
   - Inferencia con VideoMAE â†’ palabra + confianza
3. **DecisiÃ³n:**
   - Si confianza < 0.55 â†’ mensaje fallback
   - Si confianza >= 0.55 â†’ actualizar historial + llamar Gemini
4. **Gemini:** Genera respuesta empÃ¡tica (max 2 oraciones, espaÃ±ol chileno)
5. **Frontend:** Muestra palabra, confianza, respuesta y latencias

## âš™ï¸ ConfiguraciÃ³n

### **HiperparÃ¡metros del Backend (`.env`)**

| Variable | Default | DescripciÃ³n |
|----------|---------|-------------|
| `MIN_CONFIDENCE` | 0.55 | Confianza mÃ­nima para llamar a Gemini |
| `MAX_UPLOAD_SIZE_MB` | 50 | TamaÃ±o mÃ¡ximo de video |
| `MAX_HISTORY_LENGTH` | 3 | MÃ¡ximo de palabras en historial |

### **Reset de Historial AutomÃ¡tico**

El historial se resetea cuando se detecta:
- Saludos: "HELLO", "HI"
- Despedidas: "THANKS", "THANK YOU", "GOODBYE", "BYE"

## ğŸ› ï¸ TecnologÃ­as

**Backend:**
- FastAPI
- PyTorch + VideoMAE
- Google Generative AI (Gemini)
- OpenCV

**Frontend:**
- React 18
- Vite
- TypeScript
- TailwindCSS
- Axios

## ğŸ“Š Performance

- Latencia tÃ­pica VideoMAE: ~300-500ms
- Latencia tÃ­pica Gemini: ~200-400ms
- **Latencia total: <1 segundo** (ideal)

## ğŸ”’ Seguridad

- ValidaciÃ³n estricta de archivos (formato, tamaÃ±o)
- CORS configurado para orÃ­genes especÃ­ficos
- API key de Gemini en variables de entorno
- Limpieza automÃ¡tica de archivos temporales
- SanitizaciÃ³n de inputs

## ğŸ› SoluciÃ³n de Problemas

### Error: `GEMINI_API_KEY no estÃ¡ configurada`
â†’ AsegÃºrate de crear el archivo `.env` con tu API key

### Error: `No se encontrÃ³ checkpoint`
â†’ Verifica que `MODEL_PATH` en `.env` apunte al modelo correcto

### Frontend no se conecta al backend
â†’ Verifica que el backend estÃ© corriendo en `http://localhost:8000`

### CORS Error
â†’ Verifica que `CORS_ORIGINS` en `.env` incluya `http://localhost:5173`

## ğŸ“ Licencia

Este proyecto es parte de la tesis de Rafael Ovalle - UNAB

## ğŸ‘¥ Contacto

Para preguntas o soporte, contactar a: [email]

---

**Desarrollado con â¤ï¸ para la comunidad Sorda de Chile**
